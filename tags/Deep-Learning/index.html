<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tag: Deep Learning - Eshoyuan&#039; Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Eshoyuan&#039; Blog"><meta name="msapplication-TileImage" content="/img/logo.jpeg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Eshoyuan&#039; Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Eshoyuan&#039; Blog"><meta property="og:url" content="https://eshoyuan.github.io/"><meta property="og:site_name" content="Eshoyuan&#039; Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://eshoyuan.github.io/img/og_image.png"><meta property="article:author" content="Yixiao Yuan"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://eshoyuan.github.io"},"headline":"Eshoyuan' Blog","image":["https://eshoyuan.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Yixiao Yuan"},"publisher":{"@type":"Organization","name":"Eshoyuan' Blog","logo":{"@type":"ImageObject","url":"https://eshoyuan.github.io/img/logo.jpeg"}},"description":""}</script><link rel="icon" href="/img/logo.jpeg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.jpeg" alt="Eshoyuan&#039; Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">Tags</a></li><li class="is-active"><a href="#" aria-current="page">Deep Learning</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-13T16:00:00.000Z" title="2021/3/14上午12:00:00">2021-03-14</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></span><span class="level-item">7 minutes read (About 1022 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/14/NLP&amp;KG%E5%89%8D%E6%B2%BF%E8%AE%BA%E5%9D%9B%E8%AE%B2%E5%BA%A7%E7%AC%94%E8%AE%B0/">NLP&amp;KG前沿论坛讲座笔记</a></h1><div class="content"><h2 id="Part-1"><a href="#Part-1" class="headerlink" title="Part 1"></a>Part 1</h2><h3 id="AI的三种方法"><a href="#AI的三种方法" class="headerlink" title="AI的三种方法"></a>AI的三种方法</h3><p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314090131172.png" alt="image-20210314090131172" style="zoom: 33%;" /><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314090534863.png" alt="image-20210314090534863"></p>
<p>分别为符号主义、统计方法、连接主义</p>
<p>符号主义：易于解释，难以学习</p>
<p>统计方法：可解释性尚可，表达能力相对较弱，可以学习的</p>
<p>连接主义（神经网络）：效果好，难以解释</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314090553974.png" alt="image-20210314090553974" style="zoom:33%;" />

<p>三种方法的结合</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314090958192.png" alt="image-20210314090958192" style="zoom:33%;" />

<h3 id="正则表达式与神经网络相结合"><a href="#正则表达式与神经网络相结合" class="headerlink" title="正则表达式与神经网络相结合"></a>正则表达式与神经网络相结合</h3><h4 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h4><p>作者介绍的是将正则表达式与神经网络相结合。</p>
<p>单一正则表达式系统的优点：</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314091710740.png" alt="image-20210314091710740" style="zoom:33%;" />

<p>缺点：</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314091804518.png" alt="image-20210314091804518" style="zoom:33%;" />

<p>将正则表达式变成神经网络，就可以将其优点融入神经网络中，那么得到的模型就拥有了如下优点，</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314092006291.png" alt="image-20210314092006291" style="zoom:33%;" />

<p>forward的方法，其本身过程很像RNN，</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314092255805.png" style="zoom:33%;" />

<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314092328283.png" alt="image-20210314092328283" style="zoom:33%;" />

<p>于是，作者对于FA做了一些修改，得到FA-RNN。（具体过程可以参考论文）</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314092810895.png" alt="image-20210314092810895" style="zoom:33%;" />

<p>将传统RE system的Logic进行soft操作，</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314092847104.png" alt="image-20210314092847104" style="zoom:33%;" />

<p>实验结果：</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314093153699.png" alt="image-20210314093153699" style="zoom:33%;" />

<p>模型可以还原出正则表达式，PPT中左图为原始的正则表达式，右图为还原出的，虽然有一些差别，但是基本符合。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314093322116.png" alt="image-20210314093322116" style="zoom:33%;" />

<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314093330487.png" alt="image-20210314093330487" style="zoom:33%;" />



<h3 id="统计推理融入神经网络"><a href="#统计推理融入神经网络" class="headerlink" title="统计推理融入神经网络"></a>统计推理融入神经网络</h3><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314093408961.png" alt="image-20210314093408961" style="zoom:33%;" />

<h4 id="内容-1"><a href="#内容-1" class="headerlink" title="内容"></a>内容</h4><p>涉及到的一些概念：dependency parsing（依存句法分析）</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314093541130.png" alt="image-20210314093541130" style="zoom:33%;" />

<p>缺少相应基础，中间的推导没能听懂，讲的是MF\LBP的过程，然后这个过程比较像GNN，所以作者就将GNN与之结合起来构建模型。</p>
<img src="C:%5CUsers%5C16563%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210314094021096.png" alt="image-20210314094021096" style="zoom:33%;" />

<h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314094642390.png" alt="image-20210314094642390" style="zoom:33%;" />

<h3 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h3><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314094710494.png" alt="image-20210314094710494" style="zoom:33%;" />

<h2 id="Part-2"><a href="#Part-2" class="headerlink" title="Part 2"></a>Part 2</h2><p>知识图谱：一种结点和边的有向图结构。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314095830285.png" alt="image-20210314095830285" style="zoom:33%;" />

<p>知识图谱相对于语义网弱化了本体的概念，</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314100022215.png" alt="image-20210314100022215" style="zoom:33%;" />



<p>知识融合：多模态、跨语言、不一致性（真值推断）</p>
<p>（模态：每一种信息的来源或者形式，都可以称为一种模态）</p>
<p>本体匹配与实体对齐在很多研究中相互促进。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314101613218.png" alt="image-20210314101613218" style="zoom:33%;" />

<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314101755308.png" alt="image-20210314101755308" style="zoom:33%;" />

<p>把人引入实体对齐，先用机器学习生成一个初始的结果，然后通过人来检验不停的循环提高模型结果。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314102040809.png" alt="image-20210314102040809" style="zoom:33%;" />

<p>困难：知识图谱的数据不够直观，要选择合适的人，在有限的循环次数中效果最好，结果传播……</p>
<p>传递方法或偏序进行对齐推断，这样就可以不用人来推断</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314102331434.png" alt="image-20210314102331434" style="zoom:33%;" />

<p>作者的工作解决的主要是结果的传播</p>
<p>将多个图合并起来，将可能实体对齐的对放在候选集里，然后计算概率，把最有可能实体对齐对交给人去判断，形成闭环。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314102807206.png" alt="image-20210314102807206" style="zoom:33%;" />

<p>知识融合</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314103525959.png" alt="image-20210314103525959" style="zoom:33%;" />

<p>还需要建模数据源的质量。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314103756045.png" alt="image-20210314103756045" style="zoom:33%;" />

<p>长尾实体：三元组数量少的实体占了所有实体的大部分，这些实体被叫做长尾实体。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314104547060.png" alt="image-20210314104547060" style="zoom:33%;" />

<p>介绍比较火的基于表示学习的方法</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314105449989.png" alt="image-20210314105449989" style="zoom:33%;" />

<p>由于异构性不完备等原因，所以学习表示就遇到了困难。比如有的图谱没有爷爷的关系，表示为父亲的父亲，那么就是二阶邻居，但在有爷爷关系的图谱中就是一阶邻居。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314112147442.png" alt="image-20210314112147442" style="zoom:33%;" />

<h2 id="Part-3"><a href="#Part-3" class="headerlink" title="Part 3"></a>Part 3</h2><p>人机对话</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314113227668.png" alt="image-20210314113227668" style="zoom:33%;" />

<p>需要减少万能回复</p>
<img src="C:%5CUsers%5C16563%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210314113433878.png" alt="image-20210314113433878" style="zoom:33%;" />

<p>通过实验发现首词对生成结果的影响，</p>
<img src="C:%5CUsers%5C16563%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210314113554019.png" alt="image-20210314113554019" style="zoom:33%;" />

<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314113713468.png" alt="image-20210314113713468" style="zoom:33%;" />

<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314113836458.png" alt="image-20210314113836458" style="zoom:33%;" />

<p>这里联想到《Can Fine-tuning Pre-trained Models Lead to Perfect NLP? A Study of the Generalizability of Relation Extraction》中也用提到了反事实的训练。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314114056028.png" alt="image-20210314114056028" style="zoom: 33%;" />

<img src="C:%5CUsers%5C16563%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210314114234324.png" alt="image-20210314114234324" style="zoom:33%;" />

<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210314114714949.png" alt="image-20210314114714949" style="zoom:33%;" />

<h2 id="报告体会"><a href="#报告体会" class="headerlink" title="报告体会"></a>报告体会</h2><p>虽然很多领域我都没有接触过，也不是很能够听得懂，但是还是学到了不少研究的方法，也感觉到了基础的重要性。虽然如今深度学习当道，但是一些传统的方法仍然能够给我们带来很多的启发，基于这些传统的方法去搭建网络模型往往可以得到不错的结果。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-06T16:00:00.000Z" title="2021/3/7上午12:00:00">2021-03-07</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></span><span class="level-item">5 minutes read (About 694 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/07/DiagnoseRE%E5%A4%8D%E7%8E%B0/">DiagnoseRE复现</a></h1><div class="content"><p>本周对上周的代码进行了部分复现，虽然Github已经提供了源代码，但是相比于之前直接跑别人完整的程序代码还是有有一定难度的，在此记录复现的过程。</p>
<p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2009.06206">https://arxiv.org/abs/2009.06206</a></p>
<p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/zjunlp/DiagnoseRE">https://github.com/zjunlp/DiagnoseRE</a></p>
<p>由于本地无NVIDIA独显，故采用Colab进行。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>git下载源代码</p>
<p><code>git clone https://github.com/zjunlp/DiagnoseRE.git</code></p>
<p>进入目录安装依赖</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd DiagnoseRE</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<p>安装OpenNRE（一个开源的关系提取框架，项目地址<a target="_blank" rel="noopener" href="https://github.com/thunlp/OpenNRE%EF%BC%89">https://github.com/thunlp/OpenNRE）</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/thunlp/OpenNRE.git</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>

<p>利用OpenNRE自带的脚本下载wiki80数据集</p>
<p><code>bash benchmark/download_wiki80.sh</code></p>
<p>注：由于TACRED数据集下载需注册付费，故只采用wiki80进行实验。</p>
<h2 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h2><p>train.py的使用方法已在文档中给出，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">python train.py -h</span><br><span class="line">usage: train.py [-h] --model_path MODEL_PATH [--restore] --train_path</span><br><span class="line">                TRAIN_PATH --valid_path VALID_PATH --relation_path</span><br><span class="line">                RELATION_PATH [--num_epochs NUM_EPOCHS]</span><br><span class="line">                [--max_seq_len MAX_SEQ_LEN] [--batch_size BATCH_SIZE]</span><br><span class="line">                [--metric &#123;micro_f1,acc&#125;]</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  --model_path MODEL_PATH, -m MODEL_PATH</span><br><span class="line">                        Full path for saving weights during training</span><br><span class="line">  --restore             Whether to restore model weights from given model path</span><br><span class="line">  --train_path TRAIN_PATH, -t TRAIN_PATH</span><br><span class="line">                        Full path to file containing training data</span><br><span class="line">  --valid_path VALID_PATH, -v VALID_PATH</span><br><span class="line">                        Full path to file containing validation data</span><br><span class="line">  --relation_path RELATION_PATH, -r RELATION_PATH</span><br><span class="line">                        Full path to json file containing relation to index</span><br><span class="line">                        dict</span><br><span class="line">  --num_epochs NUM_EPOCHS, -e NUM_EPOCHS</span><br><span class="line">                        Number of training epochs</span><br><span class="line">  --max_seq_len MAX_SEQ_LEN, -l MAX_SEQ_LEN</span><br><span class="line">                        Maximum sequence length of bert model</span><br><span class="line">  --batch_size BATCH_SIZE, -b BATCH_SIZE</span><br><span class="line">                        Batch size for training and testing</span><br><span class="line">  --metric &#123;micro_f1,acc&#125;</span><br><span class="line">                        Metric chosen for evaluation</span><br></pre></td></tr></table></figure>
<p>进入命令行，填入参数即可开始训练，relation是一个关系字符串映射为数字的json文件，通过查看源代码，num_epochs的默认值为10，batch_size为64。</p>
<p>这里saved_model是自己创建的文件名用于保存模型的训练参数，其他path填wiki80数据集对应的文件即可。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py -m saved_model -v OpenNRE/wiki80/wiki80_val.txt -t OpenNRE/wiki80/wiki80_train.txt -r OpenNRE/wiki80/wiki80_rel2id.json</span><br></pre></td></tr></table></figure>

<p>训练用时较长，由于是第一次进行类似的工作，经验不足，比如不知道model_path是填文件地址还是目录地址，而这种情况需要训练完第一个epoch后才会报错。以后进行代码调试的时候可以减少batch size或者只取一小部分训练样本用于测试，这样加快训练速度，代码有问题可以很快发现。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>训练了近3个小时，得到的f1 score为86.2857%，与论文中的86.2%基本一致。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210305214152454.png" alt="image-20210305214152454"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-04T16:00:00.000Z" title="2021/3/5上午12:00:00">2021-03-05</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></span><span class="level-item">25 minutes read (About 3725 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Can Fine-tuning Pre-trained Models Lead to Perfect NLP? A Study of the Generalizability of Relation Extraction》 阅读笔记</a></h1><div class="content"><p>前两周在根据transformers库的文档熟悉操作，但是有种不知其所以然的感觉，本周慢下来读论文，熟悉常用的研究方法及思路，加深对pre-trained model的理解，也借助论文，了解领域的相关名词及概念。</p>
<h2 id="一些概念"><a href="#一些概念" class="headerlink" title="一些概念"></a>一些概念</h2><h3 id="Wiki80数据集"><a href="#Wiki80数据集" class="headerlink" title="Wiki80数据集"></a>Wiki80数据集</h3><p>Wiki80是由FewRel而来，而FewRel 是以 Wikipedia 作为语料库，以 Wikidata 作为知识图谱构建的，是一个大规模精标注关系抽取数据集 。</p>
<p>任务：对于给定了的句子和两个做了标注的名词，从给定的关系清单中选出最合适的关系。<br>数据集中一共包含80中关系，经统计各个关系个数均为700，合计56000个样本。</p>
<p>Wiki80数据集采用人工精标，不包含噪声。</p>
<p>样本格式：<br>例子：{“token”: [“Vahitahi”, “has”, “a”, “territorial”, “airport”, “.”], “h”: {“name”: “territorial airport”, “id”: “Q16897548”, “pos”: [3, 5]}, “t”: {“name”: “vahitahi”, “id”: “Q1811472”, “pos”: [0, 1]}, “relation”: “place served by transport hub”}</p>
<h3 id="TACRED数据集"><a href="#TACRED数据集" class="headerlink" title="TACRED数据集"></a>TACRED数据集</h3><p>TACRED是一个大规模的关系提取数据集，具有106264个示例，这些示例是通过新闻电讯和Web文本构建的，这些示例来自用于每年TAC知识库人口（TAC KBP）挑战的语料。TACRED中的示例涵盖了TAC KBP中使用的41个关系类型（例如，per：schools_attended和org：members），如果没有定义的关系则将其标记为no_relation。这些示例是通过将TACKBP和群众外包获得的。</p>
<p>在每个TACRED示例中，提供了以下注释：</p>
<ul>
<li><p>主题和客体提及的范围；</p>
</li>
<li><p>提及的类型（在 <a target="_blank" rel="noopener" href="https://stanfordnlp.github.io/CoreNLP/ner.html">Stanford NER system</a>中使用的23种细粒度类型中）；</p>
</li>
<li><p>实体之间保持的关系（在41个TAC KBP规范关系类型中），或者如果未找到任何关系，则为no_relation标签。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210228113521194.png" alt="image-20210228113521194"></p>
</li>
</ul>
<h3 id="显著图"><a href="#显著图" class="headerlink" title="显著图"></a>显著图</h3><p>显著图（Saliency Map）是一种可解释方法，最初是计算机视觉领域用于解释模型预测效果的一个工具，它的大小和原始图相同，图上的点的数值对应原图像素对预测目标类别的重要性。</p>
<p>最初的显著图是通过有监督方式计算出的模型损失对输入图像的梯度，梯度数值经过归一化处理，用于衡量每个输入单位的变化对目标输出类别概率的影响，其值越大越能反映该输入的相对重要性，即<br>$$<br>\frac{\Delta Predicted\ Class}{\Delta Pixel\ Value}<br>$$</p>
<p>下图为一个MNIST手写数字识别的例子：</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210228141308364.png" alt="image-20210228141308364"></p>
<p>这也可以用于非目标类别，比如将数字7预测为1，那么7的一横在显著图上就应该是负的，一竖则是正的。</p>
<h3 id="积分梯度"><a href="#积分梯度" class="headerlink" title="积分梯度"></a>积分梯度</h3><p>  显著图中，直接通过梯度来反映重要性，但是这在一些情况下是不适用的。比如下图，鼻子的长度对于判断是否是大象很重要，但是鼻子长度达到一定程度后，长一点短一点对于判断的影响不是很大了，那么此时梯度就接近于0。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210228141756273.png" alt="image-20210228141756273"></p>
<p>所以，采用整条梯度线的积分作为鼻子对大象分类的重要程度，将会是更合理的一种获取显著图的方式。</p>
<p>这里整个偏导被换成了变分的形式，变分边界是基线图像（可以选择不同的基线）和当前图像，变分路径可以任意选择（一般就选择线性路径插值，将原始图片x乘以0-1区间的倍率）。<br>$$<br>\phi_{i}^{I G}\left(f, x, x^{\prime}\right)=\overbrace{\left(x_{i}-x_{i}^{\prime}\right)}^{\text {Difference from baseline }} \times \int_{\alpha=0}^{1} \frac{\delta f\left(x^{\prime}+\alpha\left(x-x^{\prime}\right)\right)}{\delta x_{i}} d \alpha<br>$$<br>NLP也可以用积分梯度及显著图进行可解释性研究。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210228150157434.png" alt="image-20210228150157434"></p>
<h2 id="《Can-Fine-tuning-Pre-trained-Models-Lead-to-Perfect-NLP-A-Study-of-the-Generalizability-of-Relation-Extraction》"><a href="#《Can-Fine-tuning-Pre-trained-Models-Lead-to-Perfect-NLP-A-Study-of-the-Generalizability-of-Relation-Extraction》" class="headerlink" title="《Can Fine-tuning Pre-trained Models Lead to Perfect NLP? A Study of the Generalizability of Relation Extraction》"></a>《Can Fine-tuning Pre-trained Models Lead to Perfect NLP? A Study of the Generalizability of Relation Extraction》</h2><h3 id="摘要及介绍"><a href="#摘要及介绍" class="headerlink" title="摘要及介绍"></a>摘要及介绍</h3><p>本文是一篇关系抽取泛化性能分析的文章，作者举了一个例子来说明当前该领域研究的不足，“我们不知道模型出色的性能与其泛化能力是否预示着良好的泛化性能”，在文章中，作者提出了五个问题，</p>
<ul>
<li>Q1：模型是否在通过一些关键词进行模版匹配？</li>
<li>Q2：模型在关系抽取问题上的对抗样本表现如何？</li>
<li>Q3：模型对反事实样本的表现如何？</li>
<li>Q4：模型是否在捕捉和利用数据中的一些不存在的关联来进行预测？</li>
<li>Q5：模型是否存在语义的偏差，即模型只从实体文本或者上下文本中学习关系（例如，光靠记实体名字就能推断）？</li>
</ul>
<p>主要进行的工作如下，主要从鲁棒性（robustness）及偏差（bias）两方面进行研究。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/%E6%88%AA%E5%B1%8F2021-02-28%20%E4%B8%8A%E5%8D%8810.36.58.png" alt="截屏2021-02-28 上午10.36.58"></p>
<h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><h4 id="鲁棒性"><a href="#鲁棒性" class="headerlink" title="鲁棒性"></a>鲁棒性</h4><p>分析的主要方法如下，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210228113638024.png" alt="image-20210228113638024"></p>
<h5 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h5><p>这一部分基于CheckList工具设计了对上下文和头尾实体中的文本进行同类型随机替换的实验。作者通过随机查看生产的结果，基本标签都仍然是正确的。通过替换产生的随机样本数量大概在原样本的5～8倍，作为一种数据增强的方法，使用BERT进行微调训练和测试。</p>
<p>在Wiki80和TACRED数据集上进行实验的结果如下：</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210228130622141.png" alt="image-20210228130622141"></p>
<p>这个可以看出数据增强训练的模型在原始数据集上分数略有下降，但鲁棒性更好，这个结果很符合直觉。</p>
<h5 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h5><p>这一部分，基于OpenAttack工具包设计了适应关系抽取任务的文本对抗实验，将文本多分类拓展到关系抽取领域，并支持原有的文本对抗模型（TextFooler，PWWS，HotFlip等等）。</p>
<p>对于对抗模型了解匮乏，部分细节在系统地学习对抗模型后补充。不过，这不影响我们从实验结果中学习分析的方法。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210228135421294.png" alt="image-20210228135421294"></p>
<p>可以看到原始模型在对抗样本上表现较差，效果下降了许多；而经过对抗的训练后，在对抗样本上的效果较好，在原始数据上甚至还有更好的表现。但是可以发现对抗训练的模型在TACRED的原始数据集上表现变差了，这在Wen, Y.; Li, S.; and Jia, K. 2019. Towards Understand- ing the Regularization of Adversarial Robustness on Neural Networks .也有提及，作者认为这之间是一个平衡，还需要更多的研究。</p>
<h5 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h5><p>对于关系抽取，这里的反事实样本指的是改变句子的内容，使得句子中实体的关系从【关系A】变为【不存在A关系】（或者【没有关系】即no_relation）。</p>
<p>本文通过如下方法构造反事实样本：</p>
<ul>
<li>使用训练好的BERT模型，对句子计算了每一个token的梯度以后，去掉停用词和BERT模型的保留token（[SEP]，[CLS]，[unused0/1/2/3]等），对剩余结果按照梯度得分进行排序获得关键的token；</li>
<li>将关键token进行遮盖（使用特殊标记进行替换和直接去除效果差异不大，实际使用去除token并补齐句长的方法），得到反事实的样本，其关系标签为“非关系”（即no_relation）；</li>
<li>使用BERT模型，对反事实样本进行测试，并对训练数据进行上述方式的反事实增广后，使用模型进行微调训练和测试。</li>
</ul>
<p>需要注意的是，由于在Wiki80数据中不存在非关系，所以本部分仅针对TACRED数据集进行实验。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210228150641964.png" alt="image-20210228150641964"></p>
<p>这个例子说明为什么用积分梯度来获得反事实的样本，使用attention就达不到所需要的效果。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210305130940084.png" alt="image-20210305130940084"></p>
<p>初始模型在反事实集合上的表现不佳，而经过训练后的模型在反事实样本上表现提高较大，且在原始数据上的表现也与原始模型差距不大。</p>
<h4 id="偏差"><a href="#偏差" class="headerlink" title="偏差"></a>偏差</h4><p>分析的主要方法如下，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210228151123237.png" alt="image-20210228151123237"></p>
<h5 id="Q4"><a href="#Q4" class="headerlink" title="Q4"></a>Q4</h5><p>这一部分基于数据中存在的真实情况提出了假设，即模型会利用一些无关的词语共现情况进行辅助推理，这些词语实际上对句子表达的关系并没有实际影响。</p>
<p>TACRED数据集是通过远程监督清洗得到的，在样本的抽取过程中存在一些无关的共现（即部分词语和某种关系总是同时出现），这可能使得模型可能在训练中学习到数据偏差带来的本不存在的关联。</p>
<p>作者经过统计，发现确实存在这样的情况，所以经过人工的调整（即筛选出上述关键词中和关系无关的关键词）以后，对测试数据中按不同关系的样本，将其包含对应高频无关词进行遮盖（这里实验中用空符号对原始token进行替换，不改变原始token的位置），并使用原始模型进行测试；同时，对训练数据集按照测试集同样遮盖处理，获得的微调模型分别对原始测试数据和遮盖高频词后的测试数据进行测试，结果如下：</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210305130951312.png" alt="image-20210305130951312"></p>
<p>可以看出，经过去除高频非相关词后，原始模型的测试结果有所下降；经过同样处理的训练数据集微调训练得出的模型在基本保持对原始数据分布的效果的基础上，在新的测试集上同样具有较高的效果。</p>
<p>作者自己在博客中写到”实验后感觉，对高频词进行mask可能会破坏语句的结构，所以效果下降是否就是由于数据偏见引起的，这部分有待商榷，当然也期待会有更好的方案（如果使用词替换的方案也许更合理，但是对人工标注的要求较高）”。他自己也提到” 由于数据处理方法在训练集和测试集上统一，形成了相似的空间分布，所以微调后训练结果提升也许不是多么神奇的事情……“，如此来看，这个结果确实不是那么具有说服力，当然这个结果是符合直觉的，但是实验方法不是那么严谨。</p>
<h5 id="Q5"><a href="#Q5" class="headerlink" title="Q5"></a>Q5</h5><p>这一部分尚未完全理解，一些说法参考了作者本人博客。</p>
<p>作者参考了《More Data, More Relations, More Context and More Openness- A Review and Outlook for Relation Extraction》中模型对实体文本、上下文的实验，并提出了基于频率的实体遮盖（Frequency-based Masking）方法。</p>
<p>本文的实验同样设置了mask entity和only entity的场景，但是存在一些不同：</p>
<ul>
<li><p>mask entity的具体实现为将头尾实体进行去除，但是保留句子的头尾位置信息（即，BERT中的特殊token）；</p>
</li>
<li><p>mask entity设置了随机去除一半实体（50%），以及全部去除（100%）的场景；</p>
</li>
<li><p>mask entity设置了基于实体对频率（frequency）的场景，即出现频率越高的实体对所在的样本的遮盖率越高，以期消除模型对实体文本的“过度学习”。</p>
</li>
<li><ul>
<li>这里由于Wiki80中实体对在数据中高频率出现的现象并不明显，所以不对这一数据集进行实验，而在TACRED数据集由于其构造方式（远程监督），存在较多实体对高频出现的情形。</li>
</ul>
</li>
<li><p>设置De-biased组别，这一组别旨在检测模型在提供实体名字时预测失败的情形下，提供了上下文文本以后是否能够成功预测（即，筛选出only entity场景下分类错误样本的原始样本进行测试）。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210228152226148.png" alt="image-20210228152226148"></p>
<p>可以看出，（1）初始模型对mask entity场景的鲁棒性不足，而提供了实体名字的组别（only entity）中表现更好，这证明了模型存在“记名字”的现象；（2）经过mask增广数据训练的模型在mask entity表现提升，但依然不及原始效果，在only entity场景提升不明显或者没有提升；（3）所有mask entity增广训练的模型都在De-biased测试上表现增强，其中按频率mask的组别在De-biased测试上表现更好（当然效果区别不是很明显）。</p>
</li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>第一次读这种类型的论文，虽然没有创造性的提出多么新颖的模型，但是作者思考问题，分析问题的思路值得学习，并且这些方法是可以能够模仿的，很多结果也是十分符合直觉的。这也是第一次读关系抽取的论文，也对于关系抽取有了一定的了解。有时间希望可以复现一下作者的代码，加深理解。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-27T16:00:00.000Z" title="2021/2/28上午12:00:00">2021-02-28</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></span><span class="level-item">6 minutes read (About 867 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/28/Transformer%E5%BA%93%E5%88%9D%E6%8E%A2/">Transformer库初探(1)</a></h1><div class="content"><h1 id="Transformer库初探"><a href="#Transformer库初探" class="headerlink" title="Transformer库初探"></a>Transformer库初探</h1><p>本文主要参考<a target="_blank" rel="noopener" href="https://github.com/bentrevett/pytorch-sentiment-analysis%E4%B8%AD%E7%9A%84**6">https://github.com/bentrevett/pytorch-sentiment-analysis中的**6</a> - Transformers for Sentiment Analysis**，使用colab进行实验。</p>
<h2 id="实验内容"><a href="#实验内容" class="headerlink" title="实验内容"></a>实验内容</h2><p>使用BERT训练IMDB评论的情感分析。</p>
<h2 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>进行分词及输入长度限制，可以看到此处输入长度最长为512。（这里就出现了BERT不能处理长文本的问题，<em>CogLTX</em>: Applying BERT to Long Texts这篇论文提出了一种解决办法，后续会尝试采用这种方法再次实验）</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210207111439164.png" alt="image-20210207111439164"></p>
<p>进行一些token的处理以及标签构建。</p>
<p>实验数据从torchtext中获取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> datasets</span><br><span class="line">train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)</span><br><span class="line">train_data, valid_data = train_data.split(random_state = random.seed(SEED))</span><br></pre></td></tr></table></figure>

<p>此实验中batch_size为128。</p>
<h3 id="模型建立"><a href="#模型建立" class="headerlink" title="模型建立"></a>模型建立</h3><p>载入pre-trained model。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer, BertModel</span><br><span class="line">bert = BertModel.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>进行模型的定义以及实例化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BERTGRUSentiment</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,bert:BertModel,</span></span></span><br><span class="line"><span class="params"><span class="function">                 hidden_dim:<span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 output_dim:<span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 n_layers:<span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 bidirectional:<span class="built_in">bool</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 dropout:<span class="built_in">float</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(BERTGRUSentiment, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.bert=bert</span><br><span class="line">        embedding_dim=bert.config.to_dict()[<span class="string">&#x27;hidden_size&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.rnn=nn.GRU(embedding_dim,hidden_dim,n_layers,</span><br><span class="line">                        bidirectional=bidirectional,</span><br><span class="line">                        batch_first=<span class="literal">True</span>,</span><br><span class="line">                        dropout=<span class="number">0</span> <span class="keyword">if</span> n_layers&lt;<span class="number">2</span> <span class="keyword">else</span> dropout)</span><br><span class="line"></span><br><span class="line">        self.fc=nn.Linear(hidden_dim*<span class="number">2</span> <span class="keyword">if</span> bidirectional <span class="keyword">else</span> hidden_dim,output_dim)</span><br><span class="line"></span><br><span class="line">        self.dropout=nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,text</span>):</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            embedding=self.bert(text)[<span class="number">0</span>]</span><br><span class="line">            <span class="comment">#embeddiing:(batch,seq,embedding_dim)</span></span><br><span class="line"></span><br><span class="line">        _,hidden=self.rnn(embedding)</span><br><span class="line">        <span class="comment">#(bi*num_layers,batch,hidden_size)</span></span><br><span class="line"></span><br><span class="line">        hidden=self.dropout(torch.cat((hidden[-<span class="number">1</span>,:,:],hidden[-<span class="number">2</span>,:,:]),dim=<span class="number">1</span>) <span class="keyword">if</span> self.rnn.bidirectional <span class="keyword">else</span> hidden[-<span class="number">1</span>,:,:]) </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.fc(hidden)</span><br><span class="line">        <span class="comment">#（batch,output_dim）</span></span><br><span class="line"></span><br><span class="line">HIDDEN_DIM = <span class="number">256</span></span><br><span class="line">OUTPUT_DIM = <span class="number">1</span></span><br><span class="line">N_LAYERS = <span class="number">2</span></span><br><span class="line">BIDIRECTIONAL = <span class="literal">True</span></span><br><span class="line">DROPOUT = <span class="number">0.25</span></span><br><span class="line"></span><br><span class="line">model = BERTGRUSentiment(bert,</span><br><span class="line">                         HIDDEN_DIM,</span><br><span class="line">                         OUTPUT_DIM,</span><br><span class="line">                         N_LAYERS,</span><br><span class="line">                         BIDIRECTIONAL,</span><br><span class="line">                         DROPOUT)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在训练之前需要将模型中有关于BERT预训练的参数冻结。</p>
<p>此次实验共有2,759,169参数需要训练。</p>
<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>训练花费了较长时间，尝试使用CPU进行，无法完成。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210207144153092.png" alt="image-20210207144153092"></p>
<p>训练过程占用了大量显存。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210207115022335.png" alt="image-20210207115022335" style="zoom:67%;" />

<h3 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h3><p>第三个是我在IMDB上找的影评，可以看到对于较长的句子仍然可以正确划分其情感。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">predict_sentiment(model, tokenizer, <span class="string">&quot;This film is terrible&quot;</span>)</span><br><span class="line"><span class="comment"># 0.02264496125280857</span></span><br><span class="line">predict_sentiment(model, tokenizer, <span class="string">&quot;This film is great&quot;</span>)</span><br><span class="line"><span class="comment"># 0.9411056041717529</span></span><br><span class="line">predict_sentiment(model, tokenizer, <span class="string">&quot;People are grossly overrating this movie. It&#x27;s pretty boring for the first hour. Not even close to as entertaining as other Pixar movies. I don&#x27;t think I laughed out loud one time during the whole movie. It&#x27;s watchable, but I wouldn&#x27;t rewatch it ever again.&quot;</span>)</span><br><span class="line"><span class="comment"># 0.0345646762135478</span></span><br></pre></td></tr></table></figure>

<h3 id="实验中遇到的问题"><a href="#实验中遇到的问题" class="headerlink" title="实验中遇到的问题"></a>实验中遇到的问题</h3><p>计算loss时出现的错误，预测的batch维度与真实的batch维度不同，可能由于与参考代码部分环境版本不一致导致。</p>
<p>在程序中加入predict = predict.squeeze(-1)  即可解决问题。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210207150056020.png" alt="image-20210207150056020"></p>
<h2 id="实验收获及小结"><a href="#实验收获及小结" class="headerlink" title="实验收获及小结"></a>实验收获及小结</h2><p>上周学习了Transformer以及BERT的一些知识，本周使用Transformer库中的BERT模型进行了情感分类的实验，可以感觉到BERT的强大。同时，也能发现BERT模型相当巨大，尽管冻结了BERT模型中的参数，仍然需要训练不少的参数，GPU在这个过程中的优势彻底展现了出来。</p>
<p>当然，此次使用的BERT模型也存在不能处理长文本的问题，以本次实验为例，IMDB上很多影评的长度是超过512的，那么就需要对BERT进行一些改进，本周尚未能实现<em>CogLTX</em>: Applying BERT to Long Texts中的方法，下周继续尝试。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-20T16:00:00.000Z" title="2021/2/21上午12:00:00">2021-02-21</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></span><span class="level-item">4 minutes read (About 641 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/21/Transformer%E5%BA%93%E5%88%9D%E6%8E%A2(2)/">Transformer库初探(2)</a></h1><div class="content"><p>Transformers上提供了数千种经过预训练的模型，提供了pipeline的API方便快速实验，上周初步接触，最近主要依据官方手册进一步学习，了解熟悉整个流程。</p>
<p>本次笔记主要参考<a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers/tree/master/examples%EF%BC%8C%E5%AF%B9GLUE">https://github.com/huggingface/transformers/tree/master/examples，对GLUE</a> Benchmark进行fine-tune。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>GLUE分为九个任务，每个任务采取不同的指标</p>
<ul>
<li><p>for CoLA: <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">Matthews Correlation Coefficient</a></p>
</li>
<li><p>for MNLI (matched or mismatched): Accuracy</p>
</li>
<li><p>for MRPC: Accuracy and <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/F1_score">F1 score</a></p>
</li>
<li><p>for QNLI: Accuracy</p>
</li>
<li><p>for QQP: Accuracy and <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/F1_score">F1 score</a></p>
</li>
<li><p>for RTE: Accuracy</p>
</li>
<li><p>for SST-2: Accuracy</p>
</li>
<li><p>for STS-B: <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson Correlation Coefficient</a> and <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient">Spearman’s_Rank_Correlation_Coefficient</a></p>
</li>
<li><p>for WNLI: Accuracy</p>
</li>
</ul>
<p>下图是CoLA训练数据的一部分。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210221172828895.png" alt="image-20210221172828895" style="zoom: 67%;" />

<h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>由Transformers提供的<code>Tokenizer</code>完成，用<code>AutoTokenizer.from_pretrained</code>快速实例化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>测试一下分词的结果</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210221173833869.png" alt="image-20210221173833869"></p>
<h2 id="Fine-tune"><a href="#Fine-tune" class="headerlink" title="Fine-tune"></a>Fine-tune</h2><p>任务都是句子分类的，所以使用了<code>AutoModelForSequenceClassification</code>类，用<code>from_pretrained</code>方法下载模型，需要注意的的是MNLI是个三分类问题，STS-B是用分类方法做的回归问题，其他都是二分类问题。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification, TrainingArguments, Trainer</span><br><span class="line">num_labels = <span class="number">3</span> <span class="keyword">if</span> task.startswith(<span class="string">&quot;mnli&quot;</span>) <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">if</span> task==<span class="string">&quot;stsb&quot;</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)</span><br></pre></td></tr></table></figure>

<p>接下来设定一些训练参数，评价指标。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">metric_name = <span class="string">&quot;pearson&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;stsb&quot;</span> <span class="keyword">else</span> <span class="string">&quot;matthews_correlation&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;cola&quot;</span> <span class="keyword">else</span> <span class="string">&quot;accuracy&quot;</span></span><br><span class="line"></span><br><span class="line">args = TrainingArguments(</span><br><span class="line">    <span class="string">&quot;test-glue&quot;</span>,</span><br><span class="line">    evaluation_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=batch_size,</span><br><span class="line">    per_device_eval_batch_size=batch_size,</span><br><span class="line">    num_train_epochs=<span class="number">5</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">    load_best_model_at_end=<span class="literal">True</span>,</span><br><span class="line">    metric_for_best_model=metric_name,</span><br><span class="line">)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_metrics</span>(<span class="params">eval_pred</span>):</span></span><br><span class="line">    predictions, labels = eval_pred</span><br><span class="line">    <span class="keyword">if</span> task != <span class="string">&quot;stsb&quot;</span>:</span><br><span class="line">        predictions = np.argmax(predictions, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        predictions = predictions[:, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br></pre></td></tr></table></figure>

<p>连同数据集传递给<code>Trainer</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">validation_key = <span class="string">&quot;validation_mismatched&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli-mm&quot;</span> <span class="keyword">else</span> <span class="string">&quot;validation_matched&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli&quot;</span> <span class="keyword">else</span> <span class="string">&quot;validation&quot;</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    args,</span><br><span class="line">    train_dataset=encoded_dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=encoded_dataset[validation_key],</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>就可以开始训练了。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210221174624824.png" alt="image-20210221174624824"></p>
<h2 id="Hyperparameter-search"><a href="#Hyperparameter-search" class="headerlink" title="Hyperparameter search"></a>Hyperparameter search</h2><p>与上述过程差别不大，调用<code>hyperparameter_search</code>即可自动搜索。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_run = trainer.hyperparameter_search(n_trials=<span class="number">10</span>, direction=<span class="string">&quot;maximize&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Transformers提供了一个标准化的流程，可以很快的上手各种模型，官方文档很全。但是对于数据集预处理方面感觉自己能力有所欠缺，还是需要多读代码，并要有能够套用代码的能力。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-06T16:00:00.000Z" title="2021/2/7上午12:00:00">2021-02-07</time></span><span class="level-item"><a class="link-muted" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></span><span class="level-item">5 minutes read (About 761 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/07/%E4%BB%8EAttention%E5%88%B0Transformer%E5%86%8D%E5%88%B0BERT/">从Attention到Transformer再到BERT</a></h1><div class="content"><h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><p>《Recurrent Models of Visual Attention》这篇论文让attention机制真正火起来，该论文主要在RNN上使用attention机制进行分类。attention机制的直观理解：人在观察图像时会将注意力集中在重要的部分，attention使得机器也能够更加关注重要的部分。有点类似于自动移动CNN的Filter寻找关键特征。以下是该论文的attention模型结构，可以对比传统RNN理解。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210131084951813.png" alt="    "></p>
<p>后来attention也被广泛运用于NLP中，不过在很长一段时间，attention都与CNN/RNN共同被使用，直到《Attention Is All You Need》提出了完全基于attention机制的transformer模型。</p>
<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>模型结构如下，</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210131085751134.png" alt="image-20210131085751134" style="zoom: 33%;" />

<p><strong>Q</strong>：Positional Encoding的作用是什么？</p>
<p><strong>A</strong>：Positional Encoding这部分赋予每个位置不同的值，让模型可以拥有句子顺序信息。因为attention是并行的，所以如果不加入则会丢失顺序信息。</p>
<p><strong>Q</strong>：Multi-head attention与attention的区别？</p>
<p><strong>A</strong>：Multi-head attention相当于做了多个attention，但是每个attention关注的方面不同。</p>
<p>在transformer中，attention具体的实现如下所示，</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210131093954343.png" alt="image-20210131093954343" style="zoom:33%;" />
$$
\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^T}{\sqrt{d_k}})V
$$
缩放因子$$\sqrt{d_k}$$使得点乘结果的值变小，否则经过softmax后的梯度很小，难以反向传播。更直观的self-attention结构如下，对于输入文本，分别将每个字作为Query，加权融合文本中所有字的语义信息，得到各个字的增强语义向量。

<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210131100304286.png" alt="image-20210131100304286" style="zoom:50%;" />

<h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2><h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><p>BERT是叠加多个transformer的encoder部分组成的模型，结构如下，</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210131100708352.png" alt="image-20210131100708352" style="zoom:25%;" />

<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>对于一个如此巨大的模型，如何train是关键问题。BERT的作者提出了两种方式来训练语言模型。</p>
<h4 id="Apparent1-Masked-LM"><a href="#Apparent1-Masked-LM" class="headerlink" title="Apparent1: Masked LM"></a>Apparent1: Masked LM</h4><p>通俗地说就是在输入一句话的时候，随机地选一些要预测的词，然后用一个MASK来代替它们，让模型根据所给的标签去学习这些地方该填的词了。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210131120814196.png" alt="image-20210131120814196" style="zoom: 25%;" />

<p>由于Linear Classifier分类能力较弱，所以如果能正确分类，说明BERT抽取出来的representation很好，可以轻易地知道被MASK掉的是哪个词汇。如果两个词填在被抽去的地方意思相近，它们具有相似的embedding。</p>
<h4 id="Apparent2-Next-Sentence-Prediction"><a href="#Apparent2-Next-Sentence-Prediction" class="headerlink" title="Apparent2: Next Sentence Prediction"></a>Apparent2: Next Sentence Prediction</h4><p>判断两个句子是不是连在一起的。</p>
<img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210131121254664.png" alt="image-20210131121254664" style="zoom:25%;" />

<hr>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>[1] Mnih V, Heess N, Graves A, et al. Recurrent models of visual attention[J]. arXiv preprint arXiv:1406.6247, 2014.</li>
<li>[2] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[J]. arXiv preprint arXiv:1706.03762, 2017.</li>
<li>[3] Devlin J, Chang M W, Lee K, et al. Bert: Pre-training of deep bidirectional transformers for language understanding[J]. arXiv preprint arXiv:1810.04805, 2018.</li>
<li>[4] Hung-yi Lee.Machine Learning (2020,Spring)[EB/OL].<a target="_blank" rel="noopener" href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html,2020">http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html,2020</a>.</li>
<li>[5] 腾讯Bugly.图解BERT模型：从零开始构建BERT[EB/OL].<a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1389555,2019-01-30">https://cloud.tencent.com/developer/article/1389555,2019-01-30</a>.</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-01-24T16:00:00.000Z" title="2021/1/25上午12:00:00">2021-01-25</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/">李宏毅机器学习课程</a></span><span class="level-item">3 minutes read (About 516 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/25/2020.1.25/">The foudation of Recurrent Neural Network</a></h1><div class="content"><p>Recurrent Neural Network是一种具有记忆能力的神经网络，主要用途在NLP上，句子中的单词意思依赖于前后句子，所以需要使用RNN这种带有记忆能力的神经网络模型。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210125125335061.png"></p>
<p>Bidirectional RNN是双向的RNN，普通的RNN句子中单词的意义只依赖于之前的单词，而如果使用Bidirectional RNN神经网络则具有看整个句子的能力。</p>
<h2 id="Long-short-term-Memory-LSTM"><a href="#Long-short-term-Memory-LSTM" class="headerlink" title="Long short-term Memory(LSTM)"></a>Long short-term Memory(LSTM)</h2><p>目前来说，一般提到的RNN都指LSTM，其结构如下，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210125125651539.png"></p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210125125859443.png"></p>
<p>LSTM通过三个gate来控制输入输出以及是否遗忘，可以与RNN的模型比较着看。</p>
<h2 id="Training-RNN"><a href="#Training-RNN" class="headerlink" title="Training RNN"></a>Training RNN</h2><p>RNN的训练过程中Loss会剧烈抖动，画出它的图像可以看出会存在“悬崖”与“平原”，如图所示，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210125131237795.png"></p>
<p>这是一个简单的例子解释为什么RNN会有这样的特性</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210125131409712.png"></p>
<p>故RNN经常出现梯度消失和梯度爆炸。</p>
<p>LSTM可以拿掉error surface上比较平坦的地方，从而解决梯度消失的问题。</p>
<p><strong>Q</strong>：为什么要把RNN换成LSTM？</p>
<p><strong>A</strong>：LSTM可以解决梯度消失的问题</p>
<p><strong>Q</strong>：为什么LSTM能够解决梯度消失的问题？</p>
<p><strong>A</strong>：RNN和LSTM对memory的处理其实是不一样的：</p>
<ul>
<li><p>在RNN中，每个新的时间点，memory里的旧值都会被新值所覆盖</p>
</li>
<li><p>在LSTM中，每个新的时间点，memory里的值会乘上$f(g_f)$与新值相加</p>
<p>对RNN来说，w对memory的影响每次都会被清除，而对LSTM来说，除非forget gate被打开，否则$w$对memory的影响就不会被清除，而是一直累加保留，因此它不会有梯度消失的问题。</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-01-22T16:00:00.000Z" title="2021/1/23上午12:00:00">2021-01-23</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/">李宏毅机器学习课程</a></span><span class="level-item">4 minutes read (About 604 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/23/2021.1.23(1)/">The foundation of Convolutional Neural network</a></h1><div class="content"><p>CNN用在图像处理或类似方式表达的问题当中(比如棋盘)，一般性流程如下，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123223624454.png"></p>
<h2 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h2><p>Convolution的本质是在一个图像中不断移动一个小框，然后看这个小框内是否存在一些特征。</p>
<p>自动学习出多个Filter，然后每个Filter原来图像的matrix中移动，计算内积得到新的matrix，最后得到一个多维的结果，过程如下，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123225237277.png"></p>
<p>注：如果原图像有多个维度，则每个Filter也有同样的维度。</p>
<p>Filter的过程通过神经网络实现，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123225706182.png"></p>
<h2 id="MAX-Pooling"><a href="#MAX-Pooling" class="headerlink" title="MAX Pooling"></a>MAX Pooling</h2><p>MAX Pooling的过程类似于抽调图片的一些像素，图像整体变化不大，人类仍然可以识别，但是这个操作却减小了计算量。</p>
<p>MAX Pooling的过程是压缩Convolution得到的结果，用最大的值代替一个区域的结果。整个CNN的过程如下，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123230214549.png"></p>
<h2 id="What-does-CNN-learn？"><a href="#What-does-CNN-learn？" class="headerlink" title="What does CNN learn？"></a>What does CNN learn？</h2><p>深度学习并非完全不可理解，但是它学习到的东西和人理解的确实有所差异，比如手写数字识别问题，用训练好的网络反推最佳匹配的输入应该是什么，发现和想象的相差巨大，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123230544257.png"></p>
<h2 id="运用之妙，存乎一心"><a href="#运用之妙，存乎一心" class="headerlink" title="运用之妙，存乎一心"></a>运用之妙，存乎一心</h2><p>比如围棋，围棋如果进行MAX Pooling操作则会丢失掉许多棋子的信息，那么我们在CNN训练下围棋时就应该删去MAX Pooling操作，而事实上Alpha Go也是这么做的。</p>
<p>再比如这样的语音处理，Time上会有后续操作进行处理，而在Frequency上男女生发音音调不同，但是不影响内容一致，故在Frequency上使用Filter寻找特征。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123230947192.png"></p>
<p>词向量模型使用CNN也是同理，不需要像红色框一样进行纵向的查找。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/20210123231300.png"></p>
<p>针对不同的application要设计符合它特性的network structure，而不是生硬套用，这就是CNN架构的设计理念：</p>
<p><strong>运用之妙，存乎一心</strong></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-01-22T16:00:00.000Z" title="2021/1/23上午12:00:00">2021-01-23</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/">李宏毅机器学习课程</a></span><span class="level-item">6 minutes read (About 826 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/23/2020.1.23(2)/">深度学习中防止过拟合的几种方法</a></h1><div class="content"><p>三种防止过拟合的办法：Early stopping, Regularization, Dropout</p>
<h2 id="Early-stopping"><a href="#Early-stopping" class="headerlink" title="Early stopping"></a>Early stopping</h2><p>在Validation set上的Loss最小时中止</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/20210123215430.png"></p>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><p>L1 norm和L2 norm均可用于Regularization中，其中L2 norm较为常用，其如下式，<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="43.674ex" height="2.583ex" role="img" focusable="false" viewBox="0 -891.7 19304.1 1141.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43D" d="M447 625Q447 637 354 637H329Q323 642 323 645T325 664Q329 677 335 683H352Q393 681 498 681Q541 681 568 681T605 682T619 682Q633 682 633 672Q633 670 630 658Q626 642 623 640T604 637Q552 637 545 623Q541 610 483 376Q420 128 419 127Q397 64 333 21T195 -22Q137 -22 97 8T57 88Q57 130 80 152T132 174Q177 174 182 130Q182 98 164 80T123 56Q115 54 115 53T122 44Q148 15 197 15Q235 15 271 47T324 130Q328 142 387 380T447 625Z"></path></g><g data-mml-node="mo" transform="translate(633,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1022,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(1491,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2157.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3213.6,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(3894.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4283.6,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(4752.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5363.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(6364,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(6864,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mn" transform="translate(7364,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(7864,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mo" transform="translate(8447,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mo" transform="translate(8725,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(9003,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mo" transform="translate(9719,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="msup" transform="translate(9997,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mn" transform="translate(311,413) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(10989.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(12045.1,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(12726.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(13115.1,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(13584.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(14195.3,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(15195.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(15695.6,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mn" transform="translate(16195.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(16695.6,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="msup" transform="translate(17278.6,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mtext" transform="translate(749,413) scale(0.707)"><path data-c="54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path></g></g><g data-mml-node="mi" transform="translate(18588.1,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g></g></svg></mjx-container><br>对比L1和L2的update过程：<br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -1.909ex" xmlns="http://www.w3.org/2000/svg" width="68.065ex" height="5.056ex" role="img" focusable="false" viewBox="0 -1391 30084.6 2234.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mn" transform="translate(681,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1458.8,0)"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="msubsup" transform="translate(2014.6,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="TeXAtom" transform="translate(749,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(749,-292.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4250.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msubsup" transform="translate(5306.1,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,413) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(749,-247) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(6582.5,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(7582.8,0)"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mfrac" transform="translate(8079.8,0)"><g data-mml-node="mrow" transform="translate(401,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="msub" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><rect width="1809" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(10350.9,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(11351.2,0)"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(11848.2,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mtext" transform="translate(12431.2,0)"><path data-c="A0" d=""></path><path data-c="53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z" transform="translate(250,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(806,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1306,0)"></path></g><g data-mml-node="mo" transform="translate(14293.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msubsup" transform="translate(14682.2,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,413) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(749,-247) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(15736.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mtext" transform="translate(16125.4,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mi" transform="translate(16375.4,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mn" transform="translate(17056.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(17834.2,0)"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="msubsup" transform="translate(18390,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="TeXAtom" transform="translate(749,413) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mi" transform="translate(749,-292.4) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(20625.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(21681.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(22070.5,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(22792.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(23792.9,0)"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(24289.9,0)"><path data-c="1D706" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path></g><g data-mml-node="mo" transform="translate(24872.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="msubsup" transform="translate(25261.9,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,413) scale(0.707)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(749,-247) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(26538.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(27538.6,0)"><path data-c="1D702" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mfrac" transform="translate(28035.6,0)"><g data-mml-node="mrow" transform="translate(401,676)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="mi" transform="translate(566,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g><g data-mml-node="mrow" transform="translate(220,-686)"><g data-mml-node="mi"><path data-c="1D715" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path></g><g data-mml-node="msub" transform="translate(566,0)"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><rect width="1809" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container><br>其中Sgn(阶跃函数)为绝对值的导数。</p>
<p>L1和L2，虽然它们同样是让参数的绝对值变小，但它们做的事情其实略有不同：</p>
<ul>
<li>L1使参数绝对值变小的方式是每次update减掉一个固定的值</li>
<li>L2使参数绝对值变小的方式是每次update乘上一个小于1的固定值</li>
</ul>
<p>因此，当参数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex" xmlns="http://www.w3.org/2000/svg" width="1.62ex" height="1.027ex" role="img" focusable="false" viewBox="0 -443 716 454"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g></g></svg></mjx-container>的绝对值比较大的时候，L2会让<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex" xmlns="http://www.w3.org/2000/svg" width="1.62ex" height="1.027ex" role="img" focusable="false" viewBox="0 -443 716 454"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g></g></svg></mjx-container>下降得更快，而L1每次update只让w减去一个固定的值，train完以后可能还会有很多比较大的参数；当参数<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex" xmlns="http://www.w3.org/2000/svg" width="1.62ex" height="1.027ex" role="img" focusable="false" viewBox="0 -443 716 454"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g></g></svg></mjx-container>的绝对值比较小的时候，L2的下降速度就会变得很慢，train出来的参数平均都是比较小的，而L1每次下降一个固定的value，train出来的参数是比较sparse的，这些参数有很多是接近0的值，也会有很大的值。</p>
<p><strong>Q</strong>：为什么要让参数w绝对值变小？</p>
<p><strong>A</strong>：正则项有选择地让某些 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex" xmlns="http://www.w3.org/2000/svg" width="1.62ex" height="1.027ex" role="img" focusable="false" viewBox="0 -443 716 454"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g></g></svg></mjx-container> 变小，样本中的特征有很多，但大部分特征都是无关紧要的，只有一小部分关键的特征支撑起了整个预测模型。正则化让无关紧要的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="2.36ex" height="1.359ex" role="img" focusable="false" viewBox="0 -443 1043 600.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>变小，而作为关键特征的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="2.36ex" height="1.359ex" role="img" focusable="false" viewBox="0 -443 1043 600.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>如果变小，则可能导致损失函数急剧增大，么由此造成的损失函数的扩大将远大于从正则项上获得的微小收益，所以这些关键的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="2.36ex" height="1.359ex" role="img" focusable="false" viewBox="0 -443 1043 600.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mi" transform="translate(749,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>可以几乎不受正则项的干涉。</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>Dropout的思想和集成学习十分类似，在training的时候，每次update参数之前，我们对每一个neuron(除了最后的output layer)做sampling(抽样) ，每个neuron都有p%的几率会被丢掉，如果某个neuron被丢掉的话，跟它相连的weight也都要被丢掉，实际上就是每次update参数之前都通过抽样只保留network中的一部分neuron来做训练，最后将多次训练的不同参数乘以系数(1-p%)构成完整的网络。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123222334828.png" alt="image-20210123222334828"></p>
<p>如果network是非linear的，ensemble和dropout是不equivalent的；但是，dropout最后一个很神奇的地方是，虽然在non-linear的情况下，它是跟ensemble不相等的，但最后的结果还是会work如果network很接近linear的话，dropout所得到的performance会比较好，而ReLU和Maxout的network相对来说是比较接近于linear的，所以我们通常会把含有ReLU或Maxout的network与Dropout配合起来使用。</p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/pic.png" alt="Eshoyuan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Eshoyuan</p><p class="is-size-6 is-block">Bachelor of AI</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Nanjing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">4</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/eshoyuan" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/eshoyuan"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Zhihu" href="https://www.zhihu.com/people/eshoyuan"><i class="fab fa-zhihu"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.seu.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Southeast University</span></span><span class="level-right"><span class="level-item tag">www.seu.edu.cn</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E5%85%B6%E4%BB%96/"><span class="level-start"><span class="level-item">-其他</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/"><span class="level-start"><span class="level-item">李宏毅机器学习课程</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-14T16:00:00.000Z">2021-05-15</time></p><p class="title"><a href="/2021/05/15/2021.5.15/">关于博客</a></p><p class="categories"><a href="/categories/%E5%85%B6%E4%BB%96/">-其他</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-13T16:00:00.000Z">2021-03-14</time></p><p class="title"><a href="/2021/03/14/NLP&amp;KG%E5%89%8D%E6%B2%BF%E8%AE%BA%E5%9D%9B%E8%AE%B2%E5%BA%A7%E7%AC%94%E8%AE%B0/">NLP&amp;KG前沿论坛讲座笔记</a></p><p class="categories"><a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-06T16:00:00.000Z">2021-03-07</time></p><p class="title"><a href="/2021/03/07/DiagnoseRE%E5%A4%8D%E7%8E%B0/">DiagnoseRE复现</a></p><p class="categories"><a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-04T16:00:00.000Z">2021-03-05</time></p><p class="title"><a href="/2021/03/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">《Can Fine-tuning Pre-trained Models Lead to Perfect NLP? A Study of the Generalizability of Relation Extraction》 阅读笔记</a></p><p class="categories"><a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/02/28/Transformer%E5%BA%93%E5%88%9D%E6%8E%A2/"><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/20210515205427.png" alt="Transformer库初探(1)"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-02-27T16:00:00.000Z">2021-02-28</time></p><p class="title"><a href="/2021/02/28/Transformer%E5%BA%93%E5%88%9D%E6%8E%A2/">Transformer库初探(1)</a></p><p class="categories"><a href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/02/"><span class="level-start"><span class="level-item">February 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Paper/"><span class="tag">Paper</span><span class="tag">2</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.jpeg" alt="Eshoyuan&#039; Blog" height="28"></a><p class="is-size-7"><span>&copy; 2021 Yixiao Yuan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>