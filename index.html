<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Eshoyuan&#039; Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Eshoyuan&#039; Blog"><meta name="msapplication-TileImage" content="/img/logo.jpeg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Eshoyuan&#039; Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Eshoyuan&#039; Blog"><meta property="og:url" content="https://eshoyuan.github.io/"><meta property="og:site_name" content="Eshoyuan&#039; Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://eshoyuan.github.io/img/og_image.png"><meta property="article:author" content="Yixiao Yuan"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://eshoyuan.github.io"},"headline":"Eshoyuan' Blog","image":["https://eshoyuan.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Yixiao Yuan"},"publisher":{"@type":"Organization","name":"Eshoyuan' Blog","logo":{"@type":"ImageObject","url":"https://eshoyuan.github.io/img/logo.jpeg"}},"description":""}</script><link rel="icon" href="/img/logo.jpeg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.jpeg" alt="Eshoyuan&#039; Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-05-15T11:35:06.905Z" title="2021/5/15下午7:35:06">2021-05-15</time></span><span class="level-item">a minute read (About 121 words)</span></div></div><div class="content"><h1 id="Semi-supervised"><a href="#Semi-supervised" class="headerlink" title="Semi-supervised"></a>Semi-supervised</h1><p>运用到了两个假设</p>
<h2 id="Low-density-Separation-Assumption"><a href="#Low-density-Separation-Assumption" class="headerlink" title="Low-density Separation Assumption"></a>Low-density Separation Assumption</h2><p>假设世界非黑即白，那么我们的分界应该很清晰。</p>
<p>如下图，左边的分界就比右边的好。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210201215805063.png" alt="image-20210201215805063"></p>
<h2 id="Smoothness-Assumption"><a href="#Smoothness-Assumption" class="headerlink" title="Smoothness Assumption"></a>Smoothness Assumption</h2><p>近朱者赤近墨者黑</p>
<p>如下图，尽管$x_3$可能里$x_2$更近，但是$x_1$有连续的点过渡到$x_2$，所以$x_2$更可能和$x_1$是一类。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210201215542640.png" alt="image-20210201215542640"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-05-15T11:35:06.900Z" title="2021/5/15下午7:35:06">2021-05-15</time></span><span class="level-item">6 minutes read (About 830 words)</span></div></div><div class="content"><h1 id="Recipe-of-Deep-Learning"><a href="#Recipe-of-Deep-Learning" class="headerlink" title="Recipe of Deep Learning"></a>Recipe of Deep Learning</h1><p>三种防止过拟合的办法：Early stopping, Regularization, Dropout</p>
<h2 id="Early-stopping"><a href="#Early-stopping" class="headerlink" title="Early stopping"></a>Early stopping</h2><p>在Validation set上的Loss最小时中止</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/20210123215430.png"></p>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><p>L1 norm和L2 norm均可用于Regularization中，其中L2 norm较为常用，其如下式，<br>$$<br>J(\theta)=L(\theta)+1/2\lambda||w||^2=L(\theta)+1/2\lambda w^\text{T}w<br>$$<br>对比L1和L2的update过程：<br>$$<br>L1: w_i^{t+1}=w_i^t-\eta \frac{\partial L}{\partial w_i}-\eta \lambda \text{ Sgn}(w_i^t)\<br>L2: w_i^{t+1}=(1-\eta \lambda)w_i^t-\eta \frac{\partial L}{\partial w_i}<br>$$<br>其中Sgn(阶跃函数)为绝对值的导数。</p>
<p>L1和L2，虽然它们同样是让参数的绝对值变小，但它们做的事情其实略有不同：</p>
<ul>
<li>L1使参数绝对值变小的方式是每次update减掉一个固定的值</li>
<li>L2使参数绝对值变小的方式是每次update乘上一个小于1的固定值</li>
</ul>
<p>因此，当参数$w$的绝对值比较大的时候，L2会让$w$下降得更快，而L1每次update只让w减去一个固定的值，train完以后可能还会有很多比较大的参数；当参数$w$的绝对值比较小的时候，L2的下降速度就会变得很慢，train出来的参数平均都是比较小的，而L1每次下降一个固定的value，train出来的参数是比较sparse的，这些参数有很多是接近0的值，也会有很大的值。</p>
<p><strong>Q</strong>：为什么要让参数w绝对值变小？</p>
<p><strong>A</strong>：正则项有选择地让某些 $w$ 变小，样本中的特征有很多，但大部分特征都是无关紧要的，只有一小部分关键的特征支撑起了整个预测模型。正则化让无关紧要的$w_i$变小，而作为关键特征的$w_i$如果变小，则可能导致损失函数急剧增大，么由此造成的损失函数的扩大将远大于从正则项上获得的微小收益，所以这些关键的$ w_i $可以几乎不受正则项的干涉。</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>Dropout的思想和集成学习十分类似，在training的时候，每次update参数之前，我们对每一个neuron(除了最后的output layer)做sampling(抽样) ，每个neuron都有p%的几率会被丢掉，如果某个neuron被丢掉的话，跟它相连的weight也都要被丢掉，实际上就是每次update参数之前都通过抽样只保留network中的一部分neuron来做训练，最后将多次训练的不同参数乘以系数(1-p%)构成完整的网络。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123222334828.png" alt="image-20210123222334828"></p>
<p>如果network是非linear的，ensemble和dropout是不equivalent的；但是，dropout最后一个很神奇的地方是，虽然在non-linear的情况下，它是跟ensemble不相等的，但最后的结果还是会work如果network很接近linear的话，dropout所得到的performance会比较好，而ReLU和Maxout的network相对来说是比较接近于linear的，所以我们通常会把含有ReLU或Maxout的network与Dropout配合起来使用。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-01-31T16:00:00.000Z" title="2021/2/1上午12:00:00">2021-02-01</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/">李宏毅机器学习课程</a></span><span class="level-item">a minute read (About 119 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/01/2021.2.1/">Semi-supervised</a></h1><div class="content"><p>这里运用到了两个假设</p>
<h2 id="Low-density-Separation-Assumption"><a href="#Low-density-Separation-Assumption" class="headerlink" title="Low-density Separation Assumption"></a>Low-density Separation Assumption</h2><p>假设世界非黑即白，那么我们的分界应该很清晰。</p>
<p>如下图，左边的分界就比右边的好。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210201215805063.png"></p>
<h2 id="Smoothness-Assumption"><a href="#Smoothness-Assumption" class="headerlink" title="Smoothness Assumption"></a>Smoothness Assumption</h2><p>近朱者赤近墨者黑</p>
<p>如下图，尽管x_3可能里x_2更近，但是x_1有连续的点过渡到x_2，所以x_2更可能和x_1是一类。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210201215542640.png"></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-01-24T16:00:00.000Z" title="2021/1/25上午12:00:00">2021-01-25</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/">李宏毅机器学习课程</a></span><span class="level-item">3 minutes read (About 516 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/25/2020.1.25/">The foudation of Recurrent Neural Network</a></h1><div class="content"><p>Recurrent Neural Network是一种具有记忆能力的神经网络，主要用途在NLP上，句子中的单词意思依赖于前后句子，所以需要使用RNN这种带有记忆能力的神经网络模型。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210125125335061.png"></p>
<p>Bidirectional RNN是双向的RNN，普通的RNN句子中单词的意义只依赖于之前的单词，而如果使用Bidirectional RNN神经网络则具有看整个句子的能力。</p>
<h2 id="Long-short-term-Memory-LSTM"><a href="#Long-short-term-Memory-LSTM" class="headerlink" title="Long short-term Memory(LSTM)"></a>Long short-term Memory(LSTM)</h2><p>目前来说，一般提到的RNN都指LSTM，其结构如下，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210125125651539.png"></p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210125125859443.png"></p>
<p>LSTM通过三个gate来控制输入输出以及是否遗忘，可以与RNN的模型比较着看。</p>
<h2 id="Training-RNN"><a href="#Training-RNN" class="headerlink" title="Training RNN"></a>Training RNN</h2><p>RNN的训练过程中Loss会剧烈抖动，画出它的图像可以看出会存在“悬崖”与“平原”，如图所示，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210125131237795.png"></p>
<p>这是一个简单的例子解释为什么RNN会有这样的特性</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210125131409712.png"></p>
<p>故RNN经常出现梯度消失和梯度爆炸。</p>
<p>LSTM可以拿掉error surface上比较平坦的地方，从而解决梯度消失的问题。</p>
<p><strong>Q</strong>：为什么要把RNN换成LSTM？</p>
<p><strong>A</strong>：LSTM可以解决梯度消失的问题</p>
<p><strong>Q</strong>：为什么LSTM能够解决梯度消失的问题？</p>
<p><strong>A</strong>：RNN和LSTM对memory的处理其实是不一样的：</p>
<ul>
<li><p>在RNN中，每个新的时间点，memory里的旧值都会被新值所覆盖</p>
</li>
<li><p>在LSTM中，每个新的时间点，memory里的值会乘上$f(g_f)$与新值相加</p>
<p>对RNN来说，w对memory的影响每次都会被清除，而对LSTM来说，除非forget gate被打开，否则$w$对memory的影响就不会被清除，而是一直累加保留，因此它不会有梯度消失的问题。</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-01-22T16:00:00.000Z" title="2021/1/23上午12:00:00">2021-01-23</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/">李宏毅机器学习课程</a></span><span class="level-item">4 minutes read (About 604 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/23/2021.1.23(1)/">The foundation of Convolutional Neural network</a></h1><div class="content"><p>CNN用在图像处理或类似方式表达的问题当中(比如棋盘)，一般性流程如下，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123223624454.png"></p>
<h2 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h2><p>Convolution的本质是在一个图像中不断移动一个小框，然后看这个小框内是否存在一些特征。</p>
<p>自动学习出多个Filter，然后每个Filter原来图像的matrix中移动，计算内积得到新的matrix，最后得到一个多维的结果，过程如下，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123225237277.png"></p>
<p>注：如果原图像有多个维度，则每个Filter也有同样的维度。</p>
<p>Filter的过程通过神经网络实现，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123225706182.png"></p>
<h2 id="MAX-Pooling"><a href="#MAX-Pooling" class="headerlink" title="MAX Pooling"></a>MAX Pooling</h2><p>MAX Pooling的过程类似于抽调图片的一些像素，图像整体变化不大，人类仍然可以识别，但是这个操作却减小了计算量。</p>
<p>MAX Pooling的过程是压缩Convolution得到的结果，用最大的值代替一个区域的结果。整个CNN的过程如下，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123230214549.png"></p>
<h2 id="What-does-CNN-learn？"><a href="#What-does-CNN-learn？" class="headerlink" title="What does CNN learn？"></a>What does CNN learn？</h2><p>深度学习并非完全不可理解，但是它学习到的东西和人理解的确实有所差异，比如手写数字识别问题，用训练好的网络反推最佳匹配的输入应该是什么，发现和想象的相差巨大，</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123230544257.png"></p>
<h2 id="运用之妙，存乎一心"><a href="#运用之妙，存乎一心" class="headerlink" title="运用之妙，存乎一心"></a>运用之妙，存乎一心</h2><p>比如围棋，围棋如果进行MAX Pooling操作则会丢失掉许多棋子的信息，那么我们在CNN训练下围棋时就应该删去MAX Pooling操作，而事实上Alpha Go也是这么做的。</p>
<p>再比如这样的语音处理，Time上会有后续操作进行处理，而在Frequency上男女生发音音调不同，但是不影响内容一致，故在Frequency上使用Filter寻找特征。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/image-20210123230947192.png"></p>
<p>词向量模型使用CNN也是同理，不需要像红色框一样进行纵向的查找。</p>
<p><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/20210123231300.png"></p>
<p>针对不同的application要设计符合它特性的network structure，而不是生硬套用，这就是CNN架构的设计理念：</p>
<p><strong>应用之道，存乎一心</strong></p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/pic.png" alt="Eshoyuan"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Eshoyuan</p><p class="is-size-6 is-block">Bachelor of AI</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Nanjing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Category</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tag</p><a href="/tags"><p class="title">1</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/eshoyuan" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/eshoyuan"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Zhihu" href="https://www.zhihu.com/people/eshoyuan"><i class="fab fa-zhihu"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.seu.edu.cn/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Southeast University</span></span><span class="level-right"><span class="level-item tag">www.seu.edu.cn</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/"><span class="level-start"><span class="level-item">李宏毅机器学习课程</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-15T11:35:06.905Z">2021-05-15</time></p><p class="title"><a href="/2021/05/15/2021.1/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-15T11:35:06.900Z">2021-05-15</time></p><p class="title"><a href="/2021/05/15/2020.1.23(2)/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-31T16:00:00.000Z">2021-02-01</time></p><p class="title"><a href="/2021/02/01/2021.2.1/">Semi-supervised</a></p><p class="categories"><a href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/">李宏毅机器学习课程</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-24T16:00:00.000Z">2021-01-25</time></p><p class="title"><a href="/2021/01/25/2020.1.25/">The foudation of Recurrent Neural Network</a></p><p class="categories"><a href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/">李宏毅机器学习课程</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/01/23/2021.1.23(1)/"><img src="https://raw.githubusercontent.com/eshoyuan/pic/main/20210512213111.png" alt="The foundation of Convolutional Neural network"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-01-22T16:00:00.000Z">2021-01-23</time></p><p class="title"><a href="/2021/01/23/2021.1.23(1)/">The foundation of Convolutional Neural network</a></p><p class="categories"><a href="/categories/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B/">李宏毅机器学习课程</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/02/"><span class="level-start"><span class="level-item">February 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">January 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">3</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.jpeg" alt="Eshoyuan&#039; Blog" height="28"></a><p class="is-size-7"><span>&copy; 2021 Yixiao Yuan</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>